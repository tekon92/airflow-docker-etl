version: '2'

services:
  postgresql:
    image: docker.io/bitnami/postgresql:10
    volumes:
      - 'postgresql_data:/bitnami/postgresql'
    environment:
      - POSTGRESQL_DATABASE=bitnami_airflow
      - POSTGRESQL_USERNAME=bn_airflow
      - POSTGRESQL_PASSWORD=bitnami1
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
  redis:
    image: docker.io/bitnami/redis:6.0
    volumes:
      - 'redis_data:/bitnami'
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
  airflow-scheduler:
    # TODO: to be reverted to use proper registry/distro on T39132
    # image: docker.io/bitnami/airflow-scheduler:2
    image: docker.io/bitnami/airflow-scheduler:2.2.2-debian-10-r9
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    volumes:
      - airflow_scheduler_data:/bitnami
      - ./dags:/opt/bitnami/airflow/dags
      - logs_volume:/opt/bitnami/airflow/logs
      - ./requirements.txt:/bitnami/python/requirements.txt
  airflow-worker:
    # TODO: to be reverted to use proper registry/distro on T39132
    # image: docker.io/bitnami/airflow-worker:2
    image: docker.io/bitnami/airflow-worker:2.2.2-debian-10-r9
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
    volumes:
      - airflow_worker_data:/bitnami
      - ./dags:/opt/bitnami/airflow/dags
      - logs_volume:/opt/bitnami/airflow/logs
      - ./requirements.txt:/bitnami/python/requirements.txt
  airflow:
    image: docker.io/bitnami/airflow:2.2.2-debian-10-r8
    environment:
      - AIRFLOW_DATABASE_NAME=bitnami_airflow
      - AIRFLOW_DATABASE_USERNAME=bn_airflow
      - AIRFLOW_DATABASE_PASSWORD=bitnami1
      - AIRFLOW_EXECUTOR=CeleryExecutor
    ports:
      - '8080:8080'
    volumes:
      - airflow_data:/bitnami
      - ./dags:/opt/bitnami/airflow/dags
      - logs_volume:/opt/bitnami/airflow/logs
      - ./requirements.txt:/bitnami/python/requirements.txt
  spark:
    image: jupyter/pyspark-notebook
    ports:
      - "8888:8888"
      - "4040-4080:4040-4080"
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks/
  pg:
    image: docker.io/bitnami/postgresql:11
    env_file:
      - database.env
    ports:
      - '5433:5432'
    expose:
      - '5433'
    volumes:
      - 'pg_data:/bitnami/postgresql'
    environment:
      - 'ALLOW_EMPTY_PASSWORD=yes'
  mysql:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: 'db'
      # So you don't have to use root, but you can if you like
      MYSQL_USER: 'user'
      # You can use whatever password you like
      MYSQL_PASSWORD: 'password'
      # Password for root access
      MYSQL_ROOT_PASSWORD: 'password'
    ports:
      # <Port exposed> : < MySQL Port running inside container>
      - '3306:3306'
    expose:
      # Opens port 3306 on the container
      - '3306'
      # Where our data will be persisted
    volumes:
      - my-db:/var/lib/mysql
volumes:
  airflow_scheduler_data:
    driver: local
  airflow_worker_data:
    driver: local
  airflow_data:
    driver: local
  postgresql_data:
    driver: local
  redis_data:
    driver: local
  pg_data:
    driver: local
  my-db:
    driver: local
  logs_volume:
    driver: local
